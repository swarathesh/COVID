{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": " Deep Convolutional GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swarathesh/COVID_CSGAN_WEBAPP/blob/master/Deep_Convolutional_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Mlds1KtYI4",
        "colab_type": "text"
      },
      "source": [
        "# Deep Convolutional Generative Adversarial Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmkffznutcTl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "386d7c85-029b-4476-98a7-ef1e1a62a9f5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGZ8NcgstshX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ba6ed47-119f-4644-ff2e-59ae9bd1d386"
      },
      "source": [
        "cd /content/drive/My Drive/dataset/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NESdIxi6tYI7",
        "colab_type": "text"
      },
      "source": [
        "##### Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZu9nWCftYI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from time import time\n",
        "import os\n",
        "import pandas as pd\n",
        "# os.chdir('/content/drive/My Drive/dataset/')\n",
        "import argparse\n",
        "import math\n",
        "import re\n",
        "import itertools\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5qifSnstYJN",
        "colab_type": "text"
      },
      "source": [
        "##### Loading all file names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIjcx3qdtYJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = glob('/content/drive/My Drive/dataset/co/chest_xray/test/COVID19 /*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxSW-LzNtYJS",
        "colab_type": "text"
      },
      "source": [
        "##### Loading the covid x-ray images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bMUa5HytYJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crop(img):\n",
        "    if img.shape[0]<img.shape[1]:\n",
        "        x = img.shape[0]\n",
        "        y = img.shape[1]\n",
        "        crop_img = img[: , int(y/2-x/2):int(y/2+x/2)]\n",
        "    else:\n",
        "        x = img.shape[1]\n",
        "        y = img.shape[0]\n",
        "        crop_img = img[int(y/2-x/2):int(y/2+x/2) , :]\n",
        "\n",
        "    return crop_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNf1nv12tYJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "filelist = glob.glob('/content/drive/My Drive/dataset/co/chest_xray/test/covid19/*')\n",
        "dim = 60\n",
        "x = []\n",
        "for ix, file in enumerate(filelist): \n",
        "    image = plt.imread(file)\n",
        "    image = Image.fromarray((image * 255).astype(np.uint8)).resize((dim, dim)).convert('L')\n",
        "    image = crop(np.array(image))\n",
        "    x.append(image)\n",
        "y = np.repeat(1, len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz6ZnQF6tYJi",
        "colab_type": "text"
      },
      "source": [
        "##### pictures into arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCgawYPPtYJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.divide(np.array(x, dtype=np.float32), 255).reshape(-1, 1, 60, 60)\n",
        "y = np.array(y, dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuwk7glwzDcT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9d14489-e375-4a7e-c984-cafe35482c95"
      },
      "source": [
        "x.shape,y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((234, 1, 60, 60), (234,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv24tMk5tYJl",
        "colab_type": "text"
      },
      "source": [
        "##### targets into a 2D matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8anUfDstYJw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7edefb54-713c-47f2-c4df-af45914e32f9"
      },
      "source": [
        "print('Scaling...', end='')\n",
        "image_size = x.shape[1] * x.shape[1]\n",
        "print('\\rDone.     ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scaling...\rDone.     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yd08RsntYJy",
        "colab_type": "text"
      },
      "source": [
        "#####  tensors to CUDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSpYG_qdtYJy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28d8a405-3a6c-42c8-fbae-5485e90080ce"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    x = torch.from_numpy(x) \n",
        "    y = torch.from_numpy(y)\n",
        "    print('Tensors successfully flushed to CUDA.')\n",
        "else:\n",
        "    print('CUDA not available!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensors successfully flushed to CUDA.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWJp-r5UtYJ1",
        "colab_type": "text"
      },
      "source": [
        "##### Making a dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4UOsvVUtYJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class covid():\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.len = x.shape[0]\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return x[index], y[index].unsqueeze(0) \n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjiG6XentYJ4",
        "colab_type": "text"
      },
      "source": [
        "##### Instantiating the class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2ehQfTUtYJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = covid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ienyJF4tYJ7",
        "colab_type": "text"
      },
      "source": [
        "##### Parsing the args"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AvyuWU9tYJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30ccf61a-ccbe-4437-bc67-0c5714d7dcb9"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=5_000)\n",
        "parser.add_argument(\"--batch_size\", type=int, default=32)\n",
        "parser.add_argument(\"--lr\", type=float, default=0.001)\n",
        "parser.add_argument(\"--b1\", type=float, default=0.3)\n",
        "parser.add_argument(\"--b2\", type=float, default=0.999)\n",
        "parser.add_argument(\"--n_cpu\", type=int, default=8)\n",
        "parser.add_argument(\"--latent_dim\", type=int, default=128)\n",
        "parser.add_argument(\"--img_size\", type=int, default=60)\n",
        "parser.add_argument(\"--channels\", type=int, default=1)\n",
        "parser.add_argument(\"--sample_interval\", type=int, default=5)\n",
        "opt, unknown = parser.parse_known_args()\n",
        "print(opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(b1=0.3, b2=0.999, batch_size=32, channels=1, img_size=60, latent_dim=128, lr=0.001, n_cpu=8, n_epochs=5000, sample_interval=5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bkVsnsUtYKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuda = True if torch.cuda.is_available() else False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtYZoCKKtYKC",
        "colab_type": "text"
      },
      "source": [
        "##### Initializing the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI_1z5L7tYKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSHXmcVttYKE",
        "colab_type": "text"
      },
      "source": [
        "##### Creating the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyVGZpHbtYKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.init_size = opt.img_size // 4 \n",
        "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2))\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.l1(z)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uXr-lbBtYKI",
        "colab_type": "text"
      },
      "source": [
        "##### Creating the discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioZuX5q2tYKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(opt.channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "\n",
        "        # The height and width of downsampled image\n",
        "        ds_size = opt.img_size // (2 ** 4) # gives 3\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * 4 ** 2, 1), nn.Sigmoid()) # s'attend à (1152, 1)\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.model(img)\n",
        "        out = out.view(out.shape[0], -1) # torch.Size([64, 2048])\n",
        "        validity = self.adv_layer(out)\n",
        "\n",
        "        return validity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5I7mVyAtYKL",
        "colab_type": "text"
      },
      "source": [
        "##### Creating the loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i13bkJTLtYKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2bWwocltYKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmgk6a0ktYKS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "4a23172f-61ec-453a-da19-c85ee504ba09"
      },
      "source": [
        "# Initialize weights\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Dropout2d(p=0.25, inplace=False)\n",
              "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Dropout2d(p=0.25, inplace=False)\n",
              "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (9): Dropout2d(p=0.25, inplace=False)\n",
              "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (13): Dropout2d(p=0.25, inplace=False)\n",
              "    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (adv_layer): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=1, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qtrllu6tYKU",
        "colab_type": "text"
      },
      "source": [
        "##### dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n3WjmljtYKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configure data loader\n",
        "dataloader = torch.utils.data.DataLoader(data,\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vINg-lcZy0cz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTfBHLnNtYKW",
        "colab_type": "text"
      },
      "source": [
        "##### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0ox-3eWtYKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9916433e-ec8a-4609-8027-e51e9ba54162"
      },
      "source": [
        "for epoch in range(1, opt.n_epochs + 1):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "        \n",
        "       \n",
        "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "  \n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "        \n",
        "        if not os.path.isdir('output_co'):\n",
        "            os.mkdir('output_co')\n",
        "        \n",
        "        batches_done = epoch * len(dataloader) + i + 1\n",
        "    \n",
        "  \n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "           save_image(gen_imgs.data[:25], \"./output_co/%d.png\" % batches_done, nrow=5, normalize=True)\n",
        "\n",
        "        if epoch % 50 == 0:\n",
        "         print(\n",
        "            \"[Epoch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "            % (epoch, opt.n_epochs, d_loss.item(), g_loss.item())\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 50/5000] [D loss: 0.322191] [G loss: 1.834512]\n",
            "[Epoch 50/5000] [D loss: 0.460701] [G loss: 1.116610]\n",
            "[Epoch 50/5000] [D loss: 0.286840] [G loss: 0.985374]\n",
            "[Epoch 50/5000] [D loss: 0.608223] [G loss: 1.663139]\n",
            "[Epoch 50/5000] [D loss: 0.567585] [G loss: 2.529334]\n",
            "[Epoch 50/5000] [D loss: 0.453574] [G loss: 1.023329]\n",
            "[Epoch 50/5000] [D loss: 0.477985] [G loss: 0.829671]\n",
            "[Epoch 50/5000] [D loss: 0.233437] [G loss: 1.783875]\n",
            "[Epoch 100/5000] [D loss: 0.161954] [G loss: 1.877425]\n",
            "[Epoch 100/5000] [D loss: 0.159579] [G loss: 1.859585]\n",
            "[Epoch 100/5000] [D loss: 0.245387] [G loss: 2.367885]\n",
            "[Epoch 100/5000] [D loss: 0.166793] [G loss: 1.979897]\n",
            "[Epoch 100/5000] [D loss: 0.425091] [G loss: 2.045609]\n",
            "[Epoch 100/5000] [D loss: 0.327703] [G loss: 1.049248]\n",
            "[Epoch 100/5000] [D loss: 0.229337] [G loss: 1.249271]\n",
            "[Epoch 100/5000] [D loss: 0.657297] [G loss: 2.152554]\n",
            "[Epoch 150/5000] [D loss: 0.239035] [G loss: 2.740991]\n",
            "[Epoch 150/5000] [D loss: 0.196315] [G loss: 2.060412]\n",
            "[Epoch 150/5000] [D loss: 0.514960] [G loss: 2.141261]\n",
            "[Epoch 150/5000] [D loss: 0.249907] [G loss: 0.671764]\n",
            "[Epoch 150/5000] [D loss: 0.273980] [G loss: 2.173203]\n",
            "[Epoch 150/5000] [D loss: 0.168426] [G loss: 2.866862]\n",
            "[Epoch 150/5000] [D loss: 0.095684] [G loss: 1.917021]\n",
            "[Epoch 150/5000] [D loss: 0.200987] [G loss: 0.954742]\n",
            "[Epoch 200/5000] [D loss: 0.115829] [G loss: 3.014326]\n",
            "[Epoch 200/5000] [D loss: 0.082530] [G loss: 2.404545]\n",
            "[Epoch 200/5000] [D loss: 0.116089] [G loss: 2.161165]\n",
            "[Epoch 200/5000] [D loss: 0.171828] [G loss: 3.201467]\n",
            "[Epoch 200/5000] [D loss: 0.395041] [G loss: 3.481086]\n",
            "[Epoch 200/5000] [D loss: 0.135807] [G loss: 1.957110]\n",
            "[Epoch 200/5000] [D loss: 0.173179] [G loss: 1.446824]\n",
            "[Epoch 200/5000] [D loss: 0.449565] [G loss: 2.729147]\n",
            "[Epoch 250/5000] [D loss: 0.197198] [G loss: 2.697729]\n",
            "[Epoch 250/5000] [D loss: 0.311387] [G loss: 1.740169]\n",
            "[Epoch 250/5000] [D loss: 0.606715] [G loss: 4.087340]\n",
            "[Epoch 250/5000] [D loss: 0.201319] [G loss: 1.056777]\n",
            "[Epoch 250/5000] [D loss: 0.367069] [G loss: 1.243250]\n",
            "[Epoch 250/5000] [D loss: 0.531746] [G loss: 0.809335]\n",
            "[Epoch 250/5000] [D loss: 0.489523] [G loss: 2.237764]\n",
            "[Epoch 250/5000] [D loss: 0.347109] [G loss: 2.602947]\n",
            "[Epoch 300/5000] [D loss: 0.036761] [G loss: 3.096927]\n",
            "[Epoch 300/5000] [D loss: 0.066590] [G loss: 2.345331]\n",
            "[Epoch 300/5000] [D loss: 0.074246] [G loss: 2.041028]\n",
            "[Epoch 300/5000] [D loss: 0.129466] [G loss: 2.566578]\n",
            "[Epoch 300/5000] [D loss: 0.044626] [G loss: 3.020945]\n",
            "[Epoch 300/5000] [D loss: 0.047883] [G loss: 3.059819]\n",
            "[Epoch 300/5000] [D loss: 0.184481] [G loss: 3.989394]\n",
            "[Epoch 300/5000] [D loss: 0.629880] [G loss: 2.954640]\n",
            "[Epoch 350/5000] [D loss: 0.389562] [G loss: 2.528169]\n",
            "[Epoch 350/5000] [D loss: 0.614798] [G loss: 1.828052]\n",
            "[Epoch 350/5000] [D loss: 0.460241] [G loss: 1.002103]\n",
            "[Epoch 350/5000] [D loss: 0.616416] [G loss: 1.204947]\n",
            "[Epoch 350/5000] [D loss: 0.386207] [G loss: 1.895591]\n",
            "[Epoch 350/5000] [D loss: 0.304515] [G loss: 0.849314]\n",
            "[Epoch 350/5000] [D loss: 0.202426] [G loss: 2.114436]\n",
            "[Epoch 350/5000] [D loss: 0.037470] [G loss: 1.033258]\n",
            "[Epoch 400/5000] [D loss: 0.421123] [G loss: 1.547767]\n",
            "[Epoch 400/5000] [D loss: 0.443789] [G loss: 1.004849]\n",
            "[Epoch 400/5000] [D loss: 0.484688] [G loss: 2.845547]\n",
            "[Epoch 400/5000] [D loss: 0.256973] [G loss: 4.405085]\n",
            "[Epoch 400/5000] [D loss: 0.457964] [G loss: 2.811905]\n",
            "[Epoch 400/5000] [D loss: 0.251872] [G loss: 2.395337]\n",
            "[Epoch 400/5000] [D loss: 0.351638] [G loss: 1.807527]\n",
            "[Epoch 400/5000] [D loss: 0.125619] [G loss: 2.330702]\n",
            "[Epoch 450/5000] [D loss: 0.629305] [G loss: 1.436396]\n",
            "[Epoch 450/5000] [D loss: 0.361388] [G loss: 2.134045]\n",
            "[Epoch 450/5000] [D loss: 0.336315] [G loss: 1.036905]\n",
            "[Epoch 450/5000] [D loss: 0.225431] [G loss: 1.117635]\n",
            "[Epoch 450/5000] [D loss: 0.559054] [G loss: 0.876518]\n",
            "[Epoch 450/5000] [D loss: 0.192065] [G loss: 2.120639]\n",
            "[Epoch 450/5000] [D loss: 0.447218] [G loss: 1.376708]\n",
            "[Epoch 450/5000] [D loss: 0.348857] [G loss: 4.868129]\n",
            "[Epoch 500/5000] [D loss: 0.673319] [G loss: 0.223614]\n",
            "[Epoch 500/5000] [D loss: 0.360474] [G loss: 1.652484]\n",
            "[Epoch 500/5000] [D loss: 0.407726] [G loss: 1.635698]\n",
            "[Epoch 500/5000] [D loss: 0.672275] [G loss: 1.255206]\n",
            "[Epoch 500/5000] [D loss: 0.939956] [G loss: 3.062952]\n",
            "[Epoch 500/5000] [D loss: 0.700329] [G loss: 1.300587]\n",
            "[Epoch 500/5000] [D loss: 0.270583] [G loss: 1.795493]\n",
            "[Epoch 500/5000] [D loss: 0.361633] [G loss: 2.913476]\n",
            "[Epoch 550/5000] [D loss: 0.227034] [G loss: 2.406043]\n",
            "[Epoch 550/5000] [D loss: 0.455302] [G loss: 1.500812]\n",
            "[Epoch 550/5000] [D loss: 0.476871] [G loss: 2.334632]\n",
            "[Epoch 550/5000] [D loss: 0.115100] [G loss: 4.067759]\n",
            "[Epoch 550/5000] [D loss: 0.178368] [G loss: 1.696701]\n",
            "[Epoch 550/5000] [D loss: 0.132684] [G loss: 1.930406]\n",
            "[Epoch 550/5000] [D loss: 0.578907] [G loss: 1.644027]\n",
            "[Epoch 550/5000] [D loss: 0.063272] [G loss: 1.910400]\n",
            "[Epoch 600/5000] [D loss: 0.648009] [G loss: 2.112875]\n",
            "[Epoch 600/5000] [D loss: 0.510738] [G loss: 4.382710]\n",
            "[Epoch 600/5000] [D loss: 0.356191] [G loss: 1.685878]\n",
            "[Epoch 600/5000] [D loss: 0.338012] [G loss: 1.822588]\n",
            "[Epoch 600/5000] [D loss: 1.057813] [G loss: 0.821385]\n",
            "[Epoch 600/5000] [D loss: 0.276765] [G loss: 2.756094]\n",
            "[Epoch 600/5000] [D loss: 0.316507] [G loss: 2.891108]\n",
            "[Epoch 600/5000] [D loss: 0.838690] [G loss: 3.144369]\n",
            "[Epoch 650/5000] [D loss: 0.536898] [G loss: 1.516865]\n",
            "[Epoch 650/5000] [D loss: 0.414485] [G loss: 2.887595]\n",
            "[Epoch 650/5000] [D loss: 0.812528] [G loss: 2.485165]\n",
            "[Epoch 650/5000] [D loss: 0.448455] [G loss: 0.878666]\n",
            "[Epoch 650/5000] [D loss: 0.509612] [G loss: 1.486865]\n",
            "[Epoch 650/5000] [D loss: 0.100969] [G loss: 1.957389]\n",
            "[Epoch 650/5000] [D loss: 0.366688] [G loss: 1.256362]\n",
            "[Epoch 650/5000] [D loss: 0.569608] [G loss: 3.670634]\n",
            "[Epoch 700/5000] [D loss: 0.582797] [G loss: 0.240291]\n",
            "[Epoch 700/5000] [D loss: 0.380097] [G loss: 1.291259]\n",
            "[Epoch 700/5000] [D loss: 0.445917] [G loss: 2.038871]\n",
            "[Epoch 700/5000] [D loss: 0.419700] [G loss: 1.987997]\n",
            "[Epoch 700/5000] [D loss: 0.424196] [G loss: 0.995463]\n",
            "[Epoch 700/5000] [D loss: 0.510313] [G loss: 1.316449]\n",
            "[Epoch 700/5000] [D loss: 0.263502] [G loss: 2.896086]\n",
            "[Epoch 700/5000] [D loss: 0.411379] [G loss: 2.099220]\n",
            "[Epoch 750/5000] [D loss: 0.541307] [G loss: 1.282300]\n",
            "[Epoch 750/5000] [D loss: 0.861950] [G loss: 2.820781]\n",
            "[Epoch 750/5000] [D loss: 0.285360] [G loss: 2.534796]\n",
            "[Epoch 750/5000] [D loss: 0.381318] [G loss: 1.875945]\n",
            "[Epoch 750/5000] [D loss: 0.490352] [G loss: 2.235857]\n",
            "[Epoch 750/5000] [D loss: 0.148515] [G loss: 3.077921]\n",
            "[Epoch 750/5000] [D loss: 0.428989] [G loss: 2.827637]\n",
            "[Epoch 750/5000] [D loss: 0.959052] [G loss: 1.533040]\n",
            "[Epoch 800/5000] [D loss: 0.028112] [G loss: 4.081248]\n",
            "[Epoch 800/5000] [D loss: 0.256625] [G loss: 2.200373]\n",
            "[Epoch 800/5000] [D loss: 0.052284] [G loss: 3.680341]\n",
            "[Epoch 800/5000] [D loss: 0.178222] [G loss: 2.390474]\n",
            "[Epoch 800/5000] [D loss: 0.427228] [G loss: 3.177987]\n",
            "[Epoch 800/5000] [D loss: 0.838139] [G loss: 0.310702]\n",
            "[Epoch 800/5000] [D loss: 0.542237] [G loss: 1.469731]\n",
            "[Epoch 800/5000] [D loss: 1.116633] [G loss: 3.384425]\n",
            "[Epoch 850/5000] [D loss: 0.255095] [G loss: 3.455150]\n",
            "[Epoch 850/5000] [D loss: 0.175663] [G loss: 1.529199]\n",
            "[Epoch 850/5000] [D loss: 0.255123] [G loss: 1.517586]\n",
            "[Epoch 850/5000] [D loss: 0.317166] [G loss: 3.889685]\n",
            "[Epoch 850/5000] [D loss: 0.453512] [G loss: 3.022063]\n",
            "[Epoch 850/5000] [D loss: 0.465143] [G loss: 0.794677]\n",
            "[Epoch 850/5000] [D loss: 0.308435] [G loss: 1.335257]\n",
            "[Epoch 850/5000] [D loss: 0.063333] [G loss: 3.615188]\n",
            "[Epoch 900/5000] [D loss: 0.509440] [G loss: 2.675528]\n",
            "[Epoch 900/5000] [D loss: 0.392199] [G loss: 1.666583]\n",
            "[Epoch 900/5000] [D loss: 0.470282] [G loss: 1.615043]\n",
            "[Epoch 900/5000] [D loss: 0.295575] [G loss: 1.854009]\n",
            "[Epoch 900/5000] [D loss: 0.318778] [G loss: 0.548110]\n",
            "[Epoch 900/5000] [D loss: 0.404969] [G loss: 1.180257]\n",
            "[Epoch 900/5000] [D loss: 0.321414] [G loss: 3.632558]\n",
            "[Epoch 900/5000] [D loss: 0.242036] [G loss: 0.990265]\n",
            "[Epoch 950/5000] [D loss: 0.239669] [G loss: 3.462319]\n",
            "[Epoch 950/5000] [D loss: 0.289343] [G loss: 2.780801]\n",
            "[Epoch 950/5000] [D loss: 0.457928] [G loss: 1.799441]\n",
            "[Epoch 950/5000] [D loss: 0.615584] [G loss: 2.454808]\n",
            "[Epoch 950/5000] [D loss: 0.538164] [G loss: 1.842987]\n",
            "[Epoch 950/5000] [D loss: 0.270846] [G loss: 1.230822]\n",
            "[Epoch 950/5000] [D loss: 0.307321] [G loss: 1.264410]\n",
            "[Epoch 950/5000] [D loss: 0.316247] [G loss: 0.963213]\n",
            "[Epoch 1000/5000] [D loss: 0.236545] [G loss: 2.118450]\n",
            "[Epoch 1000/5000] [D loss: 0.265953] [G loss: 3.091470]\n",
            "[Epoch 1000/5000] [D loss: 0.510505] [G loss: 2.956348]\n",
            "[Epoch 1000/5000] [D loss: 0.171223] [G loss: 2.594280]\n",
            "[Epoch 1000/5000] [D loss: 0.617142] [G loss: 1.142334]\n",
            "[Epoch 1000/5000] [D loss: 0.846690] [G loss: 1.876802]\n",
            "[Epoch 1000/5000] [D loss: 0.861929] [G loss: 3.747375]\n",
            "[Epoch 1000/5000] [D loss: 0.659814] [G loss: 2.229582]\n",
            "[Epoch 1050/5000] [D loss: 0.501304] [G loss: 1.247811]\n",
            "[Epoch 1050/5000] [D loss: 0.714788] [G loss: 4.350733]\n",
            "[Epoch 1050/5000] [D loss: 0.201377] [G loss: 0.874293]\n",
            "[Epoch 1050/5000] [D loss: 0.497591] [G loss: 0.393699]\n",
            "[Epoch 1050/5000] [D loss: 0.582205] [G loss: 1.559808]\n",
            "[Epoch 1050/5000] [D loss: 0.532986] [G loss: 2.566659]\n",
            "[Epoch 1050/5000] [D loss: 0.587352] [G loss: 3.065831]\n",
            "[Epoch 1050/5000] [D loss: 0.153767] [G loss: 1.163011]\n",
            "[Epoch 1100/5000] [D loss: 0.390760] [G loss: 2.415274]\n",
            "[Epoch 1100/5000] [D loss: 0.204130] [G loss: 2.601696]\n",
            "[Epoch 1100/5000] [D loss: 0.236642] [G loss: 1.832708]\n",
            "[Epoch 1100/5000] [D loss: 0.472992] [G loss: 2.790027]\n",
            "[Epoch 1100/5000] [D loss: 0.648741] [G loss: 1.574290]\n",
            "[Epoch 1100/5000] [D loss: 0.970695] [G loss: 2.785225]\n",
            "[Epoch 1100/5000] [D loss: 0.315151] [G loss: 1.628694]\n",
            "[Epoch 1100/5000] [D loss: 0.410048] [G loss: 2.583633]\n",
            "[Epoch 1150/5000] [D loss: 0.091702] [G loss: 3.097370]\n",
            "[Epoch 1150/5000] [D loss: 0.083059] [G loss: 2.772605]\n",
            "[Epoch 1150/5000] [D loss: 0.334699] [G loss: 2.588413]\n",
            "[Epoch 1150/5000] [D loss: 0.148089] [G loss: 1.555123]\n",
            "[Epoch 1150/5000] [D loss: 0.301839] [G loss: 2.513839]\n",
            "[Epoch 1150/5000] [D loss: 0.526659] [G loss: 0.973315]\n",
            "[Epoch 1150/5000] [D loss: 0.290989] [G loss: 2.643220]\n",
            "[Epoch 1150/5000] [D loss: 0.738435] [G loss: 0.744538]\n",
            "[Epoch 1200/5000] [D loss: 0.151268] [G loss: 3.306184]\n",
            "[Epoch 1200/5000] [D loss: 0.340843] [G loss: 2.113709]\n",
            "[Epoch 1200/5000] [D loss: 0.192248] [G loss: 1.910077]\n",
            "[Epoch 1200/5000] [D loss: 0.663672] [G loss: 1.913604]\n",
            "[Epoch 1200/5000] [D loss: 0.604349] [G loss: 0.409429]\n",
            "[Epoch 1200/5000] [D loss: 0.448847] [G loss: 4.850505]\n",
            "[Epoch 1200/5000] [D loss: 0.436789] [G loss: 2.413439]\n",
            "[Epoch 1200/5000] [D loss: 0.872311] [G loss: 1.937307]\n",
            "[Epoch 1250/5000] [D loss: 0.667520] [G loss: 5.070184]\n",
            "[Epoch 1250/5000] [D loss: 0.400089] [G loss: 1.173051]\n",
            "[Epoch 1250/5000] [D loss: 0.551020] [G loss: 0.973434]\n",
            "[Epoch 1250/5000] [D loss: 0.293396] [G loss: 2.538214]\n",
            "[Epoch 1250/5000] [D loss: 0.240807] [G loss: 2.292400]\n",
            "[Epoch 1250/5000] [D loss: 0.461398] [G loss: 0.668875]\n",
            "[Epoch 1250/5000] [D loss: 0.349985] [G loss: 2.492129]\n",
            "[Epoch 1250/5000] [D loss: 0.492498] [G loss: 0.557605]\n",
            "[Epoch 1300/5000] [D loss: 0.095117] [G loss: 5.938972]\n",
            "[Epoch 1300/5000] [D loss: 0.668840] [G loss: 3.829188]\n",
            "[Epoch 1300/5000] [D loss: 0.535887] [G loss: 2.190743]\n",
            "[Epoch 1300/5000] [D loss: 0.130987] [G loss: 1.829690]\n",
            "[Epoch 1300/5000] [D loss: 0.289721] [G loss: 2.594134]\n",
            "[Epoch 1300/5000] [D loss: 0.281608] [G loss: 1.368031]\n",
            "[Epoch 1300/5000] [D loss: 0.234619] [G loss: 1.269572]\n",
            "[Epoch 1300/5000] [D loss: 0.599489] [G loss: 2.250398]\n",
            "[Epoch 1350/5000] [D loss: 0.144748] [G loss: 2.570776]\n",
            "[Epoch 1350/5000] [D loss: 0.351138] [G loss: 1.918020]\n",
            "[Epoch 1350/5000] [D loss: 0.390628] [G loss: 0.609080]\n",
            "[Epoch 1350/5000] [D loss: 0.597058] [G loss: 3.004871]\n",
            "[Epoch 1350/5000] [D loss: 0.222790] [G loss: 1.788715]\n",
            "[Epoch 1350/5000] [D loss: 0.425978] [G loss: 0.943009]\n",
            "[Epoch 1350/5000] [D loss: 0.276648] [G loss: 2.842262]\n",
            "[Epoch 1350/5000] [D loss: 1.212788] [G loss: 3.829180]\n",
            "[Epoch 1400/5000] [D loss: 0.114101] [G loss: 3.372703]\n",
            "[Epoch 1400/5000] [D loss: 0.260897] [G loss: 1.717637]\n",
            "[Epoch 1400/5000] [D loss: 0.447586] [G loss: 2.720299]\n",
            "[Epoch 1400/5000] [D loss: 0.391599] [G loss: 3.037256]\n",
            "[Epoch 1400/5000] [D loss: 0.220525] [G loss: 4.850217]\n",
            "[Epoch 1400/5000] [D loss: 0.185980] [G loss: 3.171920]\n",
            "[Epoch 1400/5000] [D loss: 0.190360] [G loss: 1.946267]\n",
            "[Epoch 1400/5000] [D loss: 0.786308] [G loss: 4.822114]\n",
            "[Epoch 1450/5000] [D loss: 0.558235] [G loss: 0.181079]\n",
            "[Epoch 1450/5000] [D loss: 0.121598] [G loss: 1.070916]\n",
            "[Epoch 1450/5000] [D loss: 0.161344] [G loss: 1.504673]\n",
            "[Epoch 1450/5000] [D loss: 0.083712] [G loss: 3.020135]\n",
            "[Epoch 1450/5000] [D loss: 0.167310] [G loss: 3.934381]\n",
            "[Epoch 1450/5000] [D loss: 0.212208] [G loss: 2.703094]\n",
            "[Epoch 1450/5000] [D loss: 0.159433] [G loss: 2.266983]\n",
            "[Epoch 1450/5000] [D loss: 0.565727] [G loss: 5.269979]\n",
            "[Epoch 1500/5000] [D loss: 0.598187] [G loss: 1.325572]\n",
            "[Epoch 1500/5000] [D loss: 0.208734] [G loss: 3.400140]\n",
            "[Epoch 1500/5000] [D loss: 0.442871] [G loss: 5.208233]\n",
            "[Epoch 1500/5000] [D loss: 0.281191] [G loss: 1.289301]\n",
            "[Epoch 1500/5000] [D loss: 0.308491] [G loss: 1.434105]\n",
            "[Epoch 1500/5000] [D loss: 0.159209] [G loss: 2.521160]\n",
            "[Epoch 1500/5000] [D loss: 0.445272] [G loss: 3.697972]\n",
            "[Epoch 1500/5000] [D loss: 0.289323] [G loss: 2.663580]\n",
            "[Epoch 1550/5000] [D loss: 0.627921] [G loss: 0.711522]\n",
            "[Epoch 1550/5000] [D loss: 0.762759] [G loss: 1.322965]\n",
            "[Epoch 1550/5000] [D loss: 0.854704] [G loss: 6.158627]\n",
            "[Epoch 1550/5000] [D loss: 0.073731] [G loss: 2.856399]\n",
            "[Epoch 1550/5000] [D loss: 0.189086] [G loss: 1.023018]\n",
            "[Epoch 1550/5000] [D loss: 0.256452] [G loss: 2.771012]\n",
            "[Epoch 1550/5000] [D loss: 0.243872] [G loss: 2.726286]\n",
            "[Epoch 1550/5000] [D loss: 0.543008] [G loss: 1.955203]\n",
            "[Epoch 1600/5000] [D loss: 0.280706] [G loss: 6.185639]\n",
            "[Epoch 1600/5000] [D loss: 0.146218] [G loss: 2.543426]\n",
            "[Epoch 1600/5000] [D loss: 0.191583] [G loss: 2.331757]\n",
            "[Epoch 1600/5000] [D loss: 0.312736] [G loss: 1.230067]\n",
            "[Epoch 1600/5000] [D loss: 0.271729] [G loss: 1.654587]\n",
            "[Epoch 1600/5000] [D loss: 0.135910] [G loss: 2.201502]\n",
            "[Epoch 1600/5000] [D loss: 0.358491] [G loss: 2.514751]\n",
            "[Epoch 1600/5000] [D loss: 0.165847] [G loss: 4.250869]\n",
            "[Epoch 1650/5000] [D loss: 0.173691] [G loss: 1.994236]\n",
            "[Epoch 1650/5000] [D loss: 0.141407] [G loss: 4.647875]\n",
            "[Epoch 1650/5000] [D loss: 0.519756] [G loss: 3.527227]\n",
            "[Epoch 1650/5000] [D loss: 0.387936] [G loss: 4.028680]\n",
            "[Epoch 1650/5000] [D loss: 0.171693] [G loss: 2.104085]\n",
            "[Epoch 1650/5000] [D loss: 0.366368] [G loss: 3.501715]\n",
            "[Epoch 1650/5000] [D loss: 0.334188] [G loss: 2.900308]\n",
            "[Epoch 1650/5000] [D loss: 0.217524] [G loss: 2.874201]\n",
            "[Epoch 1700/5000] [D loss: 0.292418] [G loss: 1.522264]\n",
            "[Epoch 1700/5000] [D loss: 0.205001] [G loss: 1.144869]\n",
            "[Epoch 1700/5000] [D loss: 0.416371] [G loss: 3.137951]\n",
            "[Epoch 1700/5000] [D loss: 0.265358] [G loss: 3.079756]\n",
            "[Epoch 1700/5000] [D loss: 0.157319] [G loss: 3.056910]\n",
            "[Epoch 1700/5000] [D loss: 0.250344] [G loss: 3.580580]\n",
            "[Epoch 1700/5000] [D loss: 0.079207] [G loss: 3.009983]\n",
            "[Epoch 1700/5000] [D loss: 0.056255] [G loss: 3.110882]\n",
            "[Epoch 1750/5000] [D loss: 0.226888] [G loss: 3.617074]\n",
            "[Epoch 1750/5000] [D loss: 0.376763] [G loss: 4.557698]\n",
            "[Epoch 1750/5000] [D loss: 0.757651] [G loss: 1.942462]\n",
            "[Epoch 1750/5000] [D loss: 0.166624] [G loss: 0.903523]\n",
            "[Epoch 1750/5000] [D loss: 0.300791] [G loss: 0.717061]\n",
            "[Epoch 1750/5000] [D loss: 0.557038] [G loss: 1.135128]\n",
            "[Epoch 1750/5000] [D loss: 0.288909] [G loss: 1.915917]\n",
            "[Epoch 1750/5000] [D loss: 0.744497] [G loss: 1.255546]\n",
            "[Epoch 1800/5000] [D loss: 0.298137] [G loss: 3.100726]\n",
            "[Epoch 1800/5000] [D loss: 0.285515] [G loss: 2.095518]\n",
            "[Epoch 1800/5000] [D loss: 0.434985] [G loss: 2.329270]\n",
            "[Epoch 1800/5000] [D loss: 0.494816] [G loss: 1.085569]\n",
            "[Epoch 1800/5000] [D loss: 0.138898] [G loss: 3.342061]\n",
            "[Epoch 1800/5000] [D loss: 0.502989] [G loss: 4.568045]\n",
            "[Epoch 1800/5000] [D loss: 0.360629] [G loss: 1.403651]\n",
            "[Epoch 1800/5000] [D loss: 0.034617] [G loss: 4.153130]\n",
            "[Epoch 1850/5000] [D loss: 0.363892] [G loss: 2.892706]\n",
            "[Epoch 1850/5000] [D loss: 0.238863] [G loss: 2.540048]\n",
            "[Epoch 1850/5000] [D loss: 0.377265] [G loss: 1.618424]\n",
            "[Epoch 1850/5000] [D loss: 0.236153] [G loss: 4.471053]\n",
            "[Epoch 1850/5000] [D loss: 0.337539] [G loss: 1.530230]\n",
            "[Epoch 1850/5000] [D loss: 0.235022] [G loss: 5.803714]\n",
            "[Epoch 1850/5000] [D loss: 0.465581] [G loss: 1.205567]\n",
            "[Epoch 1850/5000] [D loss: 0.083938] [G loss: 3.408623]\n",
            "[Epoch 1900/5000] [D loss: 0.331854] [G loss: 2.676045]\n",
            "[Epoch 1900/5000] [D loss: 0.084412] [G loss: 1.741268]\n",
            "[Epoch 1900/5000] [D loss: 0.274589] [G loss: 2.519525]\n",
            "[Epoch 1900/5000] [D loss: 0.234597] [G loss: 1.842413]\n",
            "[Epoch 1900/5000] [D loss: 0.269616] [G loss: 1.276668]\n",
            "[Epoch 1900/5000] [D loss: 0.368881] [G loss: 1.427263]\n",
            "[Epoch 1900/5000] [D loss: 0.299350] [G loss: 1.777076]\n",
            "[Epoch 1900/5000] [D loss: 0.153678] [G loss: 2.271477]\n",
            "[Epoch 1950/5000] [D loss: 0.917132] [G loss: 2.221096]\n",
            "[Epoch 1950/5000] [D loss: 0.165738] [G loss: 3.529901]\n",
            "[Epoch 1950/5000] [D loss: 0.119612] [G loss: 3.372873]\n",
            "[Epoch 1950/5000] [D loss: 0.571453] [G loss: 3.103662]\n",
            "[Epoch 1950/5000] [D loss: 0.177683] [G loss: 3.295012]\n",
            "[Epoch 1950/5000] [D loss: 0.310189] [G loss: 1.464862]\n",
            "[Epoch 1950/5000] [D loss: 0.110591] [G loss: 1.151126]\n",
            "[Epoch 1950/5000] [D loss: 0.127464] [G loss: 4.470446]\n",
            "[Epoch 2000/5000] [D loss: 0.328061] [G loss: 1.743801]\n",
            "[Epoch 2000/5000] [D loss: 0.478984] [G loss: 3.017665]\n",
            "[Epoch 2000/5000] [D loss: 0.067937] [G loss: 2.516959]\n",
            "[Epoch 2000/5000] [D loss: 0.201834] [G loss: 2.135719]\n",
            "[Epoch 2000/5000] [D loss: 0.223622] [G loss: 4.708074]\n",
            "[Epoch 2000/5000] [D loss: 0.251250] [G loss: 2.396590]\n",
            "[Epoch 2000/5000] [D loss: 0.193191] [G loss: 0.695723]\n",
            "[Epoch 2000/5000] [D loss: 0.084680] [G loss: 1.469621]\n",
            "[Epoch 2050/5000] [D loss: 0.195076] [G loss: 4.115389]\n",
            "[Epoch 2050/5000] [D loss: 0.266509] [G loss: 5.355669]\n",
            "[Epoch 2050/5000] [D loss: 0.139379] [G loss: 1.091810]\n",
            "[Epoch 2050/5000] [D loss: 0.367458] [G loss: 2.809172]\n",
            "[Epoch 2050/5000] [D loss: 0.158898] [G loss: 5.527312]\n",
            "[Epoch 2050/5000] [D loss: 0.227419] [G loss: 2.631352]\n",
            "[Epoch 2050/5000] [D loss: 0.256478] [G loss: 2.520944]\n",
            "[Epoch 2050/5000] [D loss: 0.502861] [G loss: 1.476480]\n",
            "[Epoch 2100/5000] [D loss: 0.088381] [G loss: 2.434428]\n",
            "[Epoch 2100/5000] [D loss: 0.392713] [G loss: 2.087361]\n",
            "[Epoch 2100/5000] [D loss: 0.126324] [G loss: 1.977010]\n",
            "[Epoch 2100/5000] [D loss: 0.182086] [G loss: 4.340152]\n",
            "[Epoch 2100/5000] [D loss: 0.130845] [G loss: 4.235561]\n",
            "[Epoch 2100/5000] [D loss: 0.620478] [G loss: 3.645572]\n",
            "[Epoch 2100/5000] [D loss: 0.150676] [G loss: 1.314622]\n",
            "[Epoch 2100/5000] [D loss: 0.156768] [G loss: 3.449374]\n",
            "[Epoch 2150/5000] [D loss: 0.088165] [G loss: 4.325581]\n",
            "[Epoch 2150/5000] [D loss: 0.381934] [G loss: 2.479124]\n",
            "[Epoch 2150/5000] [D loss: 0.253359] [G loss: 3.173033]\n",
            "[Epoch 2150/5000] [D loss: 0.356305] [G loss: 1.612954]\n",
            "[Epoch 2150/5000] [D loss: 0.696325] [G loss: 3.799122]\n",
            "[Epoch 2150/5000] [D loss: 0.209453] [G loss: 1.497128]\n",
            "[Epoch 2150/5000] [D loss: 0.163294] [G loss: 1.492476]\n",
            "[Epoch 2150/5000] [D loss: 0.390147] [G loss: 3.285474]\n",
            "[Epoch 2200/5000] [D loss: 0.300690] [G loss: 1.640391]\n",
            "[Epoch 2200/5000] [D loss: 0.245583] [G loss: 1.031790]\n",
            "[Epoch 2200/5000] [D loss: 0.903282] [G loss: 2.245428]\n",
            "[Epoch 2200/5000] [D loss: 0.245613] [G loss: 5.186050]\n",
            "[Epoch 2200/5000] [D loss: 0.303996] [G loss: 4.900091]\n",
            "[Epoch 2200/5000] [D loss: 0.225130] [G loss: 2.167409]\n",
            "[Epoch 2200/5000] [D loss: 0.252767] [G loss: 2.942980]\n",
            "[Epoch 2200/5000] [D loss: 0.146221] [G loss: 4.610014]\n",
            "[Epoch 2250/5000] [D loss: 0.182107] [G loss: 3.112162]\n",
            "[Epoch 2250/5000] [D loss: 0.093276] [G loss: 4.359951]\n",
            "[Epoch 2250/5000] [D loss: 0.229055] [G loss: 1.093795]\n",
            "[Epoch 2250/5000] [D loss: 0.144032] [G loss: 2.590465]\n",
            "[Epoch 2250/5000] [D loss: 0.220133] [G loss: 2.356704]\n",
            "[Epoch 2250/5000] [D loss: 0.168218] [G loss: 5.805438]\n",
            "[Epoch 2250/5000] [D loss: 0.289279] [G loss: 4.100167]\n",
            "[Epoch 2250/5000] [D loss: 0.275950] [G loss: 2.487600]\n",
            "[Epoch 2300/5000] [D loss: 0.092823] [G loss: 3.582326]\n",
            "[Epoch 2300/5000] [D loss: 0.354718] [G loss: 2.168581]\n",
            "[Epoch 2300/5000] [D loss: 0.901856] [G loss: 3.222568]\n",
            "[Epoch 2300/5000] [D loss: 0.179261] [G loss: 2.034163]\n",
            "[Epoch 2300/5000] [D loss: 1.052978] [G loss: 0.497068]\n",
            "[Epoch 2300/5000] [D loss: 0.225069] [G loss: 3.341907]\n",
            "[Epoch 2300/5000] [D loss: 0.831060] [G loss: 2.034515]\n",
            "[Epoch 2300/5000] [D loss: 0.193549] [G loss: 2.384734]\n",
            "[Epoch 2350/5000] [D loss: 0.583701] [G loss: 1.148796]\n",
            "[Epoch 2350/5000] [D loss: 0.274839] [G loss: 1.922918]\n",
            "[Epoch 2350/5000] [D loss: 0.113661] [G loss: 4.951325]\n",
            "[Epoch 2350/5000] [D loss: 0.338385] [G loss: 5.647680]\n",
            "[Epoch 2350/5000] [D loss: 0.465420] [G loss: 0.840434]\n",
            "[Epoch 2350/5000] [D loss: 0.422575] [G loss: 2.403038]\n",
            "[Epoch 2350/5000] [D loss: 0.078542] [G loss: 2.387183]\n",
            "[Epoch 2350/5000] [D loss: 0.121940] [G loss: 5.977189]\n",
            "[Epoch 2400/5000] [D loss: 0.129232] [G loss: 2.157323]\n",
            "[Epoch 2400/5000] [D loss: 0.352468] [G loss: 2.706889]\n",
            "[Epoch 2400/5000] [D loss: 0.139459] [G loss: 3.679865]\n",
            "[Epoch 2400/5000] [D loss: 0.269786] [G loss: 4.092620]\n",
            "[Epoch 2400/5000] [D loss: 0.111380] [G loss: 5.169224]\n",
            "[Epoch 2400/5000] [D loss: 0.814709] [G loss: 3.901890]\n",
            "[Epoch 2400/5000] [D loss: 0.141371] [G loss: 3.493235]\n",
            "[Epoch 2400/5000] [D loss: 0.033957] [G loss: 2.948881]\n",
            "[Epoch 2450/5000] [D loss: 0.214951] [G loss: 3.983037]\n",
            "[Epoch 2450/5000] [D loss: 0.215962] [G loss: 3.052178]\n",
            "[Epoch 2450/5000] [D loss: 0.585565] [G loss: 2.931835]\n",
            "[Epoch 2450/5000] [D loss: 0.266585] [G loss: 2.079669]\n",
            "[Epoch 2450/5000] [D loss: 0.058967] [G loss: 3.189280]\n",
            "[Epoch 2450/5000] [D loss: 0.146184] [G loss: 3.675115]\n",
            "[Epoch 2450/5000] [D loss: 0.359705] [G loss: 3.508380]\n",
            "[Epoch 2450/5000] [D loss: 0.267167] [G loss: 0.619250]\n",
            "[Epoch 2500/5000] [D loss: 0.210024] [G loss: 1.580780]\n",
            "[Epoch 2500/5000] [D loss: 1.035315] [G loss: 0.587758]\n",
            "[Epoch 2500/5000] [D loss: 0.108119] [G loss: 3.546037]\n",
            "[Epoch 2500/5000] [D loss: 0.133370] [G loss: 4.574789]\n",
            "[Epoch 2500/5000] [D loss: 0.272827] [G loss: 5.240294]\n",
            "[Epoch 2500/5000] [D loss: 0.534074] [G loss: 2.155241]\n",
            "[Epoch 2500/5000] [D loss: 0.130591] [G loss: 2.718874]\n",
            "[Epoch 2500/5000] [D loss: 0.275247] [G loss: 4.570806]\n",
            "[Epoch 2550/5000] [D loss: 0.125318] [G loss: 1.665247]\n",
            "[Epoch 2550/5000] [D loss: 0.159277] [G loss: 1.260511]\n",
            "[Epoch 2550/5000] [D loss: 0.092762] [G loss: 2.456157]\n",
            "[Epoch 2550/5000] [D loss: 0.340035] [G loss: 2.856941]\n",
            "[Epoch 2550/5000] [D loss: 0.298874] [G loss: 1.752851]\n",
            "[Epoch 2550/5000] [D loss: 0.322543] [G loss: 2.638125]\n",
            "[Epoch 2550/5000] [D loss: 0.240787] [G loss: 2.324878]\n",
            "[Epoch 2550/5000] [D loss: 0.038782] [G loss: 4.956120]\n",
            "[Epoch 2600/5000] [D loss: 0.359647] [G loss: 1.435004]\n",
            "[Epoch 2600/5000] [D loss: 0.393372] [G loss: 4.031797]\n",
            "[Epoch 2600/5000] [D loss: 0.352314] [G loss: 0.654220]\n",
            "[Epoch 2600/5000] [D loss: 0.141407] [G loss: 3.860540]\n",
            "[Epoch 2600/5000] [D loss: 0.458888] [G loss: 3.096513]\n",
            "[Epoch 2600/5000] [D loss: 0.122835] [G loss: 1.768624]\n",
            "[Epoch 2600/5000] [D loss: 0.172110] [G loss: 4.153273]\n",
            "[Epoch 2600/5000] [D loss: 0.309492] [G loss: 5.850828]\n",
            "[Epoch 2650/5000] [D loss: 0.215425] [G loss: 2.445024]\n",
            "[Epoch 2650/5000] [D loss: 0.276827] [G loss: 4.009149]\n",
            "[Epoch 2650/5000] [D loss: 0.794529] [G loss: 3.406499]\n",
            "[Epoch 2650/5000] [D loss: 0.131110] [G loss: 1.091055]\n",
            "[Epoch 2650/5000] [D loss: 0.272409] [G loss: 1.925111]\n",
            "[Epoch 2650/5000] [D loss: 0.263743] [G loss: 1.519769]\n",
            "[Epoch 2650/5000] [D loss: 0.121976] [G loss: 2.919204]\n",
            "[Epoch 2650/5000] [D loss: 0.129763] [G loss: 3.271761]\n",
            "[Epoch 2700/5000] [D loss: 1.053162] [G loss: 0.589946]\n",
            "[Epoch 2700/5000] [D loss: 0.420280] [G loss: 1.873808]\n",
            "[Epoch 2700/5000] [D loss: 0.115037] [G loss: 3.376186]\n",
            "[Epoch 2700/5000] [D loss: 0.201420] [G loss: 2.963451]\n",
            "[Epoch 2700/5000] [D loss: 0.145440] [G loss: 2.129628]\n",
            "[Epoch 2700/5000] [D loss: 0.141504] [G loss: 2.829977]\n",
            "[Epoch 2700/5000] [D loss: 0.114830] [G loss: 4.814364]\n",
            "[Epoch 2700/5000] [D loss: 0.702676] [G loss: 5.520432]\n",
            "[Epoch 2750/5000] [D loss: 0.411269] [G loss: 1.705806]\n",
            "[Epoch 2750/5000] [D loss: 0.250726] [G loss: 1.191762]\n",
            "[Epoch 2750/5000] [D loss: 0.123519] [G loss: 1.892351]\n",
            "[Epoch 2750/5000] [D loss: 0.172346] [G loss: 3.483627]\n",
            "[Epoch 2750/5000] [D loss: 0.330913] [G loss: 4.149865]\n",
            "[Epoch 2750/5000] [D loss: 0.267229] [G loss: 2.563237]\n",
            "[Epoch 2750/5000] [D loss: 0.432278] [G loss: 3.629770]\n",
            "[Epoch 2750/5000] [D loss: 0.125758] [G loss: 4.892815]\n",
            "[Epoch 2800/5000] [D loss: 0.102416] [G loss: 2.419466]\n",
            "[Epoch 2800/5000] [D loss: 0.233946] [G loss: 1.534624]\n",
            "[Epoch 2800/5000] [D loss: 0.139143] [G loss: 4.809301]\n",
            "[Epoch 2800/5000] [D loss: 0.368781] [G loss: 4.574211]\n",
            "[Epoch 2800/5000] [D loss: 0.372917] [G loss: 1.294490]\n",
            "[Epoch 2800/5000] [D loss: 0.491398] [G loss: 1.272463]\n",
            "[Epoch 2800/5000] [D loss: 0.081938] [G loss: 1.957285]\n",
            "[Epoch 2800/5000] [D loss: 0.245817] [G loss: 2.863613]\n",
            "[Epoch 2850/5000] [D loss: 0.157623] [G loss: 2.444260]\n",
            "[Epoch 2850/5000] [D loss: 0.361968] [G loss: 5.258428]\n",
            "[Epoch 2850/5000] [D loss: 0.196280] [G loss: 4.929947]\n",
            "[Epoch 2850/5000] [D loss: 0.134067] [G loss: 2.473129]\n",
            "[Epoch 2850/5000] [D loss: 0.264482] [G loss: 2.739462]\n",
            "[Epoch 2850/5000] [D loss: 0.100061] [G loss: 5.067704]\n",
            "[Epoch 2850/5000] [D loss: 0.184999] [G loss: 2.581491]\n",
            "[Epoch 2850/5000] [D loss: 0.193678] [G loss: 2.208485]\n",
            "[Epoch 2900/5000] [D loss: 0.099557] [G loss: 3.446806]\n",
            "[Epoch 2900/5000] [D loss: 0.312338] [G loss: 4.815095]\n",
            "[Epoch 2900/5000] [D loss: 0.230190] [G loss: 3.840515]\n",
            "[Epoch 2900/5000] [D loss: 0.180381] [G loss: 1.716453]\n",
            "[Epoch 2900/5000] [D loss: 0.370859] [G loss: 2.238599]\n",
            "[Epoch 2900/5000] [D loss: 0.376588] [G loss: 1.524996]\n",
            "[Epoch 2900/5000] [D loss: 1.122919] [G loss: 7.788338]\n",
            "[Epoch 2900/5000] [D loss: 0.060235] [G loss: 2.593307]\n",
            "[Epoch 2950/5000] [D loss: 0.250066] [G loss: 1.309985]\n",
            "[Epoch 2950/5000] [D loss: 0.349898] [G loss: 1.644228]\n",
            "[Epoch 2950/5000] [D loss: 0.357685] [G loss: 4.459484]\n",
            "[Epoch 2950/5000] [D loss: 0.225768] [G loss: 3.261377]\n",
            "[Epoch 2950/5000] [D loss: 0.140890] [G loss: 3.908338]\n",
            "[Epoch 2950/5000] [D loss: 0.241967] [G loss: 1.990115]\n",
            "[Epoch 2950/5000] [D loss: 0.189232] [G loss: 3.070879]\n",
            "[Epoch 2950/5000] [D loss: 0.194251] [G loss: 1.824914]\n",
            "[Epoch 3000/5000] [D loss: 0.246294] [G loss: 0.977772]\n",
            "[Epoch 3000/5000] [D loss: 0.121474] [G loss: 0.936382]\n",
            "[Epoch 3000/5000] [D loss: 0.426055] [G loss: 0.672980]\n",
            "[Epoch 3000/5000] [D loss: 0.408514] [G loss: 2.609208]\n",
            "[Epoch 3000/5000] [D loss: 0.168187] [G loss: 3.839209]\n",
            "[Epoch 3000/5000] [D loss: 0.101172] [G loss: 6.343423]\n",
            "[Epoch 3000/5000] [D loss: 0.217864] [G loss: 1.052376]\n",
            "[Epoch 3000/5000] [D loss: 0.229105] [G loss: 3.825532]\n",
            "[Epoch 3050/5000] [D loss: 0.316913] [G loss: 3.638309]\n",
            "[Epoch 3050/5000] [D loss: 0.253595] [G loss: 3.524980]\n",
            "[Epoch 3050/5000] [D loss: 0.072027] [G loss: 2.209607]\n",
            "[Epoch 3050/5000] [D loss: 0.226832] [G loss: 2.592553]\n",
            "[Epoch 3050/5000] [D loss: 0.149252] [G loss: 5.055779]\n",
            "[Epoch 3050/5000] [D loss: 0.156602] [G loss: 2.603318]\n",
            "[Epoch 3050/5000] [D loss: 0.134071] [G loss: 2.501261]\n",
            "[Epoch 3050/5000] [D loss: 0.281714] [G loss: 4.698892]\n",
            "[Epoch 3100/5000] [D loss: 0.089898] [G loss: 2.182787]\n",
            "[Epoch 3100/5000] [D loss: 0.610329] [G loss: 5.038600]\n",
            "[Epoch 3100/5000] [D loss: 0.130041] [G loss: 1.649054]\n",
            "[Epoch 3100/5000] [D loss: 0.252873] [G loss: 1.876499]\n",
            "[Epoch 3100/5000] [D loss: 0.217468] [G loss: 3.970599]\n",
            "[Epoch 3100/5000] [D loss: 0.116544] [G loss: 3.560220]\n",
            "[Epoch 3100/5000] [D loss: 0.174401] [G loss: 3.859932]\n",
            "[Epoch 3100/5000] [D loss: 0.223971] [G loss: 4.995756]\n",
            "[Epoch 3150/5000] [D loss: 0.172157] [G loss: 1.876472]\n",
            "[Epoch 3150/5000] [D loss: 0.086088] [G loss: 2.118143]\n",
            "[Epoch 3150/5000] [D loss: 0.201983] [G loss: 3.413520]\n",
            "[Epoch 3150/5000] [D loss: 0.295237] [G loss: 2.755681]\n",
            "[Epoch 3150/5000] [D loss: 0.106536] [G loss: 3.920852]\n",
            "[Epoch 3150/5000] [D loss: 0.237266] [G loss: 4.919615]\n",
            "[Epoch 3150/5000] [D loss: 0.229215] [G loss: 3.297059]\n",
            "[Epoch 3150/5000] [D loss: 0.277311] [G loss: 1.224720]\n",
            "[Epoch 3200/5000] [D loss: 1.095153] [G loss: 2.998410]\n",
            "[Epoch 3200/5000] [D loss: 0.192225] [G loss: 4.986651]\n",
            "[Epoch 3200/5000] [D loss: 0.022514] [G loss: 4.681905]\n",
            "[Epoch 3200/5000] [D loss: 0.118390] [G loss: 3.169382]\n",
            "[Epoch 3200/5000] [D loss: 0.277170] [G loss: 2.397801]\n",
            "[Epoch 3200/5000] [D loss: 0.058038] [G loss: 1.197329]\n",
            "[Epoch 3200/5000] [D loss: 0.508213] [G loss: 1.136007]\n",
            "[Epoch 3200/5000] [D loss: 0.161825] [G loss: 4.732887]\n",
            "[Epoch 3250/5000] [D loss: 0.089911] [G loss: 3.075974]\n",
            "[Epoch 3250/5000] [D loss: 0.309018] [G loss: 3.329454]\n",
            "[Epoch 3250/5000] [D loss: 0.211423] [G loss: 5.697902]\n",
            "[Epoch 3250/5000] [D loss: 0.078436] [G loss: 4.126228]\n",
            "[Epoch 3250/5000] [D loss: 0.070782] [G loss: 3.204207]\n",
            "[Epoch 3250/5000] [D loss: 0.137592] [G loss: 3.206631]\n",
            "[Epoch 3250/5000] [D loss: 0.189856] [G loss: 1.235976]\n",
            "[Epoch 3250/5000] [D loss: 0.088834] [G loss: 2.290486]\n",
            "[Epoch 3300/5000] [D loss: 0.277562] [G loss: 1.652679]\n",
            "[Epoch 3300/5000] [D loss: 0.101034] [G loss: 4.526261]\n",
            "[Epoch 3300/5000] [D loss: 0.209000] [G loss: 2.553831]\n",
            "[Epoch 3300/5000] [D loss: 0.021947] [G loss: 3.985362]\n",
            "[Epoch 3300/5000] [D loss: 0.490187] [G loss: 1.905657]\n",
            "[Epoch 3300/5000] [D loss: 0.561810] [G loss: 1.124073]\n",
            "[Epoch 3300/5000] [D loss: 0.242098] [G loss: 4.582350]\n",
            "[Epoch 3300/5000] [D loss: 0.163607] [G loss: 3.897871]\n",
            "[Epoch 3350/5000] [D loss: 0.245148] [G loss: 2.079941]\n",
            "[Epoch 3350/5000] [D loss: 0.071740] [G loss: 2.116816]\n",
            "[Epoch 3350/5000] [D loss: 0.454674] [G loss: 2.467589]\n",
            "[Epoch 3350/5000] [D loss: 0.109447] [G loss: 1.302827]\n",
            "[Epoch 3350/5000] [D loss: 0.063254] [G loss: 4.743687]\n",
            "[Epoch 3350/5000] [D loss: 0.207505] [G loss: 2.297462]\n",
            "[Epoch 3350/5000] [D loss: 0.249926] [G loss: 4.955390]\n",
            "[Epoch 3350/5000] [D loss: 0.100953] [G loss: 5.395876]\n",
            "[Epoch 3400/5000] [D loss: 0.080902] [G loss: 5.850320]\n",
            "[Epoch 3400/5000] [D loss: 0.312061] [G loss: 4.377542]\n",
            "[Epoch 3400/5000] [D loss: 0.096060] [G loss: 2.088832]\n",
            "[Epoch 3400/5000] [D loss: 0.383941] [G loss: 4.116499]\n",
            "[Epoch 3400/5000] [D loss: 0.149294] [G loss: 2.095972]\n",
            "[Epoch 3400/5000] [D loss: 0.273294] [G loss: 1.740513]\n",
            "[Epoch 3400/5000] [D loss: 0.161286] [G loss: 2.461252]\n",
            "[Epoch 3400/5000] [D loss: 0.333334] [G loss: 4.300618]\n",
            "[Epoch 3450/5000] [D loss: 0.161575] [G loss: 3.952543]\n",
            "[Epoch 3450/5000] [D loss: 0.465577] [G loss: 5.197858]\n",
            "[Epoch 3450/5000] [D loss: 0.188393] [G loss: 2.948083]\n",
            "[Epoch 3450/5000] [D loss: 0.166703] [G loss: 3.997001]\n",
            "[Epoch 3450/5000] [D loss: 0.088478] [G loss: 6.221415]\n",
            "[Epoch 3450/5000] [D loss: 0.319451] [G loss: 4.082829]\n",
            "[Epoch 3450/5000] [D loss: 0.188192] [G loss: 5.282490]\n",
            "[Epoch 3450/5000] [D loss: 0.710837] [G loss: 5.088274]\n",
            "[Epoch 3500/5000] [D loss: 0.086595] [G loss: 6.149258]\n",
            "[Epoch 3500/5000] [D loss: 0.153917] [G loss: 2.212487]\n",
            "[Epoch 3500/5000] [D loss: 0.432790] [G loss: 1.643822]\n",
            "[Epoch 3500/5000] [D loss: 0.123137] [G loss: 2.329825]\n",
            "[Epoch 3500/5000] [D loss: 0.133117] [G loss: 3.083142]\n",
            "[Epoch 3500/5000] [D loss: 0.100453] [G loss: 2.197170]\n",
            "[Epoch 3500/5000] [D loss: 0.162427] [G loss: 2.073319]\n",
            "[Epoch 3500/5000] [D loss: 0.782032] [G loss: 4.954621]\n",
            "[Epoch 3550/5000] [D loss: 0.097001] [G loss: 4.199216]\n",
            "[Epoch 3550/5000] [D loss: 0.051375] [G loss: 4.468609]\n",
            "[Epoch 3550/5000] [D loss: 0.120049] [G loss: 1.287026]\n",
            "[Epoch 3550/5000] [D loss: 0.165474] [G loss: 1.985726]\n",
            "[Epoch 3550/5000] [D loss: 0.156649] [G loss: 4.429812]\n",
            "[Epoch 3550/5000] [D loss: 0.496092] [G loss: 3.616488]\n",
            "[Epoch 3550/5000] [D loss: 0.117471] [G loss: 3.129208]\n",
            "[Epoch 3550/5000] [D loss: 0.048336] [G loss: 2.608239]\n",
            "[Epoch 3600/5000] [D loss: 0.303954] [G loss: 4.841064]\n",
            "[Epoch 3600/5000] [D loss: 0.092638] [G loss: 3.643984]\n",
            "[Epoch 3600/5000] [D loss: 0.225955] [G loss: 1.567878]\n",
            "[Epoch 3600/5000] [D loss: 0.076566] [G loss: 4.103868]\n",
            "[Epoch 3600/5000] [D loss: 0.046622] [G loss: 2.212089]\n",
            "[Epoch 3600/5000] [D loss: 0.006047] [G loss: 6.370265]\n",
            "[Epoch 3600/5000] [D loss: 0.303070] [G loss: 6.795663]\n",
            "[Epoch 3600/5000] [D loss: 0.036113] [G loss: 4.163987]\n",
            "[Epoch 3650/5000] [D loss: 0.101671] [G loss: 2.967591]\n",
            "[Epoch 3650/5000] [D loss: 0.085598] [G loss: 3.331263]\n",
            "[Epoch 3650/5000] [D loss: 0.115072] [G loss: 4.050728]\n",
            "[Epoch 3650/5000] [D loss: 0.037927] [G loss: 3.119338]\n",
            "[Epoch 3650/5000] [D loss: 0.200833] [G loss: 4.335370]\n",
            "[Epoch 3650/5000] [D loss: 0.081307] [G loss: 4.118114]\n",
            "[Epoch 3650/5000] [D loss: 0.061358] [G loss: 3.278887]\n",
            "[Epoch 3650/5000] [D loss: 0.271032] [G loss: 3.321565]\n",
            "[Epoch 3700/5000] [D loss: 0.127384] [G loss: 3.170514]\n",
            "[Epoch 3700/5000] [D loss: 0.432016] [G loss: 2.406602]\n",
            "[Epoch 3700/5000] [D loss: 0.042131] [G loss: 5.909410]\n",
            "[Epoch 3700/5000] [D loss: 0.075605] [G loss: 4.124843]\n",
            "[Epoch 3700/5000] [D loss: 0.140513] [G loss: 3.480114]\n",
            "[Epoch 3700/5000] [D loss: 0.144923] [G loss: 5.018816]\n",
            "[Epoch 3700/5000] [D loss: 0.030521] [G loss: 2.575119]\n",
            "[Epoch 3700/5000] [D loss: 0.044126] [G loss: 7.643788]\n",
            "[Epoch 3750/5000] [D loss: 0.072382] [G loss: 3.061983]\n",
            "[Epoch 3750/5000] [D loss: 0.269095] [G loss: 2.787576]\n",
            "[Epoch 3750/5000] [D loss: 0.059947] [G loss: 2.865441]\n",
            "[Epoch 3750/5000] [D loss: 0.170263] [G loss: 5.622375]\n",
            "[Epoch 3750/5000] [D loss: 0.082110] [G loss: 3.927936]\n",
            "[Epoch 3750/5000] [D loss: 0.476280] [G loss: 1.363104]\n",
            "[Epoch 3750/5000] [D loss: 0.706474] [G loss: 4.530001]\n",
            "[Epoch 3750/5000] [D loss: 0.101135] [G loss: 2.593293]\n",
            "[Epoch 3800/5000] [D loss: 0.615776] [G loss: 5.516989]\n",
            "[Epoch 3800/5000] [D loss: 0.128977] [G loss: 1.619750]\n",
            "[Epoch 3800/5000] [D loss: 0.727607] [G loss: 3.064049]\n",
            "[Epoch 3800/5000] [D loss: 0.356063] [G loss: 8.225608]\n",
            "[Epoch 3800/5000] [D loss: 0.106146] [G loss: 4.019690]\n",
            "[Epoch 3800/5000] [D loss: 0.097265] [G loss: 4.321603]\n",
            "[Epoch 3800/5000] [D loss: 0.467392] [G loss: 3.453503]\n",
            "[Epoch 3800/5000] [D loss: 1.855313] [G loss: 7.812578]\n",
            "[Epoch 3850/5000] [D loss: 0.536633] [G loss: 0.586851]\n",
            "[Epoch 3850/5000] [D loss: 0.593586] [G loss: 2.884658]\n",
            "[Epoch 3850/5000] [D loss: 0.150476] [G loss: 6.554832]\n",
            "[Epoch 3850/5000] [D loss: 0.462247] [G loss: 5.943912]\n",
            "[Epoch 3850/5000] [D loss: 0.336872] [G loss: 1.007061]\n",
            "[Epoch 3850/5000] [D loss: 0.300280] [G loss: 3.402793]\n",
            "[Epoch 3850/5000] [D loss: 0.100718] [G loss: 2.434565]\n",
            "[Epoch 3850/5000] [D loss: 0.421002] [G loss: 3.352598]\n",
            "[Epoch 3900/5000] [D loss: 0.189317] [G loss: 2.418737]\n",
            "[Epoch 3900/5000] [D loss: 0.111472] [G loss: 3.185940]\n",
            "[Epoch 3900/5000] [D loss: 0.147738] [G loss: 6.056880]\n",
            "[Epoch 3900/5000] [D loss: 0.017290] [G loss: 3.927859]\n",
            "[Epoch 3900/5000] [D loss: 0.158581] [G loss: 2.436881]\n",
            "[Epoch 3900/5000] [D loss: 0.417507] [G loss: 3.383383]\n",
            "[Epoch 3900/5000] [D loss: 0.300465] [G loss: 2.376404]\n",
            "[Epoch 3900/5000] [D loss: 0.051622] [G loss: 3.342896]\n",
            "[Epoch 3950/5000] [D loss: 0.088928] [G loss: 0.929696]\n",
            "[Epoch 3950/5000] [D loss: 0.282013] [G loss: 3.899922]\n",
            "[Epoch 3950/5000] [D loss: 0.665374] [G loss: 3.922652]\n",
            "[Epoch 3950/5000] [D loss: 0.023503] [G loss: 1.725779]\n",
            "[Epoch 3950/5000] [D loss: 0.849064] [G loss: 1.015638]\n",
            "[Epoch 3950/5000] [D loss: 0.046232] [G loss: 3.234226]\n",
            "[Epoch 3950/5000] [D loss: 0.152231] [G loss: 5.272225]\n",
            "[Epoch 3950/5000] [D loss: 0.003465] [G loss: 6.597324]\n",
            "[Epoch 4000/5000] [D loss: 0.039480] [G loss: 3.512666]\n",
            "[Epoch 4000/5000] [D loss: 0.239429] [G loss: 1.871676]\n",
            "[Epoch 4000/5000] [D loss: 0.050853] [G loss: 2.869387]\n",
            "[Epoch 4000/5000] [D loss: 0.020744] [G loss: 4.188468]\n",
            "[Epoch 4000/5000] [D loss: 0.011442] [G loss: 4.762496]\n",
            "[Epoch 4000/5000] [D loss: 0.071640] [G loss: 4.972450]\n",
            "[Epoch 4000/5000] [D loss: 0.182048] [G loss: 2.663589]\n",
            "[Epoch 4000/5000] [D loss: 0.091854] [G loss: 5.745640]\n",
            "[Epoch 4050/5000] [D loss: 0.460957] [G loss: 3.803759]\n",
            "[Epoch 4050/5000] [D loss: 0.246992] [G loss: 5.594979]\n",
            "[Epoch 4050/5000] [D loss: 0.449721] [G loss: 2.403010]\n",
            "[Epoch 4050/5000] [D loss: 0.228391] [G loss: 4.070931]\n",
            "[Epoch 4050/5000] [D loss: 0.078595] [G loss: 5.421593]\n",
            "[Epoch 4050/5000] [D loss: 0.357371] [G loss: 5.578279]\n",
            "[Epoch 4050/5000] [D loss: 0.220452] [G loss: 2.754050]\n",
            "[Epoch 4050/5000] [D loss: 0.685490] [G loss: 1.395746]\n",
            "[Epoch 4100/5000] [D loss: 0.105004] [G loss: 5.494027]\n",
            "[Epoch 4100/5000] [D loss: 0.097645] [G loss: 6.570836]\n",
            "[Epoch 4100/5000] [D loss: 0.047843] [G loss: 1.883204]\n",
            "[Epoch 4100/5000] [D loss: 0.011835] [G loss: 2.386715]\n",
            "[Epoch 4100/5000] [D loss: 0.067399] [G loss: 2.839077]\n",
            "[Epoch 4100/5000] [D loss: 0.035664] [G loss: 2.834591]\n",
            "[Epoch 4100/5000] [D loss: 0.285300] [G loss: 1.136661]\n",
            "[Epoch 4100/5000] [D loss: 0.059006] [G loss: 4.789834]\n",
            "[Epoch 4150/5000] [D loss: 0.239892] [G loss: 2.679494]\n",
            "[Epoch 4150/5000] [D loss: 0.363615] [G loss: 5.353460]\n",
            "[Epoch 4150/5000] [D loss: 0.048618] [G loss: 5.344005]\n",
            "[Epoch 4150/5000] [D loss: 0.081975] [G loss: 4.921357]\n",
            "[Epoch 4150/5000] [D loss: 0.089222] [G loss: 4.280622]\n",
            "[Epoch 4150/5000] [D loss: 0.481709] [G loss: 3.909660]\n",
            "[Epoch 4150/5000] [D loss: 0.379778] [G loss: 4.185638]\n",
            "[Epoch 4150/5000] [D loss: 0.503428] [G loss: 2.572250]\n",
            "[Epoch 4200/5000] [D loss: 0.598634] [G loss: 1.870585]\n",
            "[Epoch 4200/5000] [D loss: 0.145057] [G loss: 2.583360]\n",
            "[Epoch 4200/5000] [D loss: 0.083252] [G loss: 5.770642]\n",
            "[Epoch 4200/5000] [D loss: 0.181626] [G loss: 5.509170]\n",
            "[Epoch 4200/5000] [D loss: 0.074208] [G loss: 3.333690]\n",
            "[Epoch 4200/5000] [D loss: 0.251163] [G loss: 2.637844]\n",
            "[Epoch 4200/5000] [D loss: 0.055221] [G loss: 3.978467]\n",
            "[Epoch 4200/5000] [D loss: 0.182820] [G loss: 1.949234]\n",
            "[Epoch 4250/5000] [D loss: 0.042446] [G loss: 2.859562]\n",
            "[Epoch 4250/5000] [D loss: 0.019651] [G loss: 3.982467]\n",
            "[Epoch 4250/5000] [D loss: 0.356898] [G loss: 2.407314]\n",
            "[Epoch 4250/5000] [D loss: 0.065572] [G loss: 6.187538]\n",
            "[Epoch 4250/5000] [D loss: 0.276992] [G loss: 5.257586]\n",
            "[Epoch 4250/5000] [D loss: 0.191464] [G loss: 4.848481]\n",
            "[Epoch 4250/5000] [D loss: 0.178349] [G loss: 2.068189]\n",
            "[Epoch 4250/5000] [D loss: 0.014367] [G loss: 4.212368]\n",
            "[Epoch 4300/5000] [D loss: 0.033696] [G loss: 6.563062]\n",
            "[Epoch 4300/5000] [D loss: 0.369656] [G loss: 5.767132]\n",
            "[Epoch 4300/5000] [D loss: 0.119620] [G loss: 3.870013]\n",
            "[Epoch 4300/5000] [D loss: 0.006008] [G loss: 3.995940]\n",
            "[Epoch 4300/5000] [D loss: 0.138473] [G loss: 2.579269]\n",
            "[Epoch 4300/5000] [D loss: 0.378201] [G loss: 2.518862]\n",
            "[Epoch 4300/5000] [D loss: 0.053075] [G loss: 6.877729]\n",
            "[Epoch 4300/5000] [D loss: 0.709635] [G loss: 3.799355]\n",
            "[Epoch 4350/5000] [D loss: 0.166505] [G loss: 1.741280]\n",
            "[Epoch 4350/5000] [D loss: 0.112302] [G loss: 1.430075]\n",
            "[Epoch 4350/5000] [D loss: 0.342608] [G loss: 1.370492]\n",
            "[Epoch 4350/5000] [D loss: 0.244826] [G loss: 4.219841]\n",
            "[Epoch 4350/5000] [D loss: 0.055009] [G loss: 2.534748]\n",
            "[Epoch 4350/5000] [D loss: 0.249420] [G loss: 2.505482]\n",
            "[Epoch 4350/5000] [D loss: 0.148997] [G loss: 4.794957]\n",
            "[Epoch 4350/5000] [D loss: 2.801059] [G loss: 4.347568]\n",
            "[Epoch 4400/5000] [D loss: 0.060243] [G loss: 5.681932]\n",
            "[Epoch 4400/5000] [D loss: 0.056592] [G loss: 4.083912]\n",
            "[Epoch 4400/5000] [D loss: 0.094201] [G loss: 2.137645]\n",
            "[Epoch 4400/5000] [D loss: 0.080723] [G loss: 6.874035]\n",
            "[Epoch 4400/5000] [D loss: 0.256308] [G loss: 2.283158]\n",
            "[Epoch 4400/5000] [D loss: 0.131863] [G loss: 1.813760]\n",
            "[Epoch 4400/5000] [D loss: 0.300745] [G loss: 0.658004]\n",
            "[Epoch 4400/5000] [D loss: 0.556573] [G loss: 4.174155]\n",
            "[Epoch 4450/5000] [D loss: 0.093531] [G loss: 2.181498]\n",
            "[Epoch 4450/5000] [D loss: 0.109150] [G loss: 1.952031]\n",
            "[Epoch 4450/5000] [D loss: 0.809043] [G loss: 2.170717]\n",
            "[Epoch 4450/5000] [D loss: 0.521533] [G loss: 6.734456]\n",
            "[Epoch 4450/5000] [D loss: 0.077100] [G loss: 3.253022]\n",
            "[Epoch 4450/5000] [D loss: 0.093654] [G loss: 4.315351]\n",
            "[Epoch 4450/5000] [D loss: 0.144104] [G loss: 4.179527]\n",
            "[Epoch 4450/5000] [D loss: 0.218860] [G loss: 2.188031]\n",
            "[Epoch 4500/5000] [D loss: 0.047684] [G loss: 6.223103]\n",
            "[Epoch 4500/5000] [D loss: 0.003171] [G loss: 6.281848]\n",
            "[Epoch 4500/5000] [D loss: 1.118753] [G loss: 6.713147]\n",
            "[Epoch 4500/5000] [D loss: 0.589654] [G loss: 2.511106]\n",
            "[Epoch 4500/5000] [D loss: 0.300000] [G loss: 3.808875]\n",
            "[Epoch 4500/5000] [D loss: 0.268610] [G loss: 6.048158]\n",
            "[Epoch 4500/5000] [D loss: 0.117558] [G loss: 3.946462]\n",
            "[Epoch 4500/5000] [D loss: 0.051872] [G loss: 4.246827]\n",
            "[Epoch 4550/5000] [D loss: 0.060156] [G loss: 2.853859]\n",
            "[Epoch 4550/5000] [D loss: 0.092353] [G loss: 4.656283]\n",
            "[Epoch 4550/5000] [D loss: 0.168352] [G loss: 3.111983]\n",
            "[Epoch 4550/5000] [D loss: 0.036192] [G loss: 3.781181]\n",
            "[Epoch 4550/5000] [D loss: 0.085346] [G loss: 4.787981]\n",
            "[Epoch 4550/5000] [D loss: 0.224258] [G loss: 3.697744]\n",
            "[Epoch 4550/5000] [D loss: 0.041188] [G loss: 3.342675]\n",
            "[Epoch 4550/5000] [D loss: 0.010615] [G loss: 1.505543]\n",
            "[Epoch 4600/5000] [D loss: 0.559583] [G loss: 4.085183]\n",
            "[Epoch 4600/5000] [D loss: 0.099766] [G loss: 0.965278]\n",
            "[Epoch 4600/5000] [D loss: 0.076670] [G loss: 0.738332]\n",
            "[Epoch 4600/5000] [D loss: 0.433359] [G loss: 1.311885]\n",
            "[Epoch 4600/5000] [D loss: 0.221149] [G loss: 4.963850]\n",
            "[Epoch 4600/5000] [D loss: 0.132106] [G loss: 5.233629]\n",
            "[Epoch 4600/5000] [D loss: 0.083790] [G loss: 4.840784]\n",
            "[Epoch 4600/5000] [D loss: 0.149691] [G loss: 4.730446]\n",
            "[Epoch 4650/5000] [D loss: 0.171216] [G loss: 2.348595]\n",
            "[Epoch 4650/5000] [D loss: 0.142128] [G loss: 1.902935]\n",
            "[Epoch 4650/5000] [D loss: 0.045505] [G loss: 1.108208]\n",
            "[Epoch 4650/5000] [D loss: 0.019133] [G loss: 5.583199]\n",
            "[Epoch 4650/5000] [D loss: 0.027873] [G loss: 3.102790]\n",
            "[Epoch 4650/5000] [D loss: 0.156652] [G loss: 2.507482]\n",
            "[Epoch 4650/5000] [D loss: 0.035496] [G loss: 4.369936]\n",
            "[Epoch 4650/5000] [D loss: 0.212197] [G loss: 3.224993]\n",
            "[Epoch 4700/5000] [D loss: 0.147105] [G loss: 4.355824]\n",
            "[Epoch 4700/5000] [D loss: 0.693810] [G loss: 7.884856]\n",
            "[Epoch 4700/5000] [D loss: 0.183245] [G loss: 3.678158]\n",
            "[Epoch 4700/5000] [D loss: 0.106321] [G loss: 3.334893]\n",
            "[Epoch 4700/5000] [D loss: 0.127683] [G loss: 2.338109]\n",
            "[Epoch 4700/5000] [D loss: 0.211349] [G loss: 3.828629]\n",
            "[Epoch 4700/5000] [D loss: 0.324879] [G loss: 4.370449]\n",
            "[Epoch 4700/5000] [D loss: 0.046376] [G loss: 6.888168]\n",
            "[Epoch 4750/5000] [D loss: 0.072555] [G loss: 2.744318]\n",
            "[Epoch 4750/5000] [D loss: 0.692640] [G loss: 4.348270]\n",
            "[Epoch 4750/5000] [D loss: 0.043108] [G loss: 4.966068]\n",
            "[Epoch 4750/5000] [D loss: 0.265023] [G loss: 3.055052]\n",
            "[Epoch 4750/5000] [D loss: 0.201933] [G loss: 4.682331]\n",
            "[Epoch 4750/5000] [D loss: 0.257131] [G loss: 2.210133]\n",
            "[Epoch 4750/5000] [D loss: 0.025042] [G loss: 2.967676]\n",
            "[Epoch 4750/5000] [D loss: 0.107542] [G loss: 4.041841]\n",
            "[Epoch 4800/5000] [D loss: 0.057434] [G loss: 1.438404]\n",
            "[Epoch 4800/5000] [D loss: 0.084326] [G loss: 4.261761]\n",
            "[Epoch 4800/5000] [D loss: 0.016167] [G loss: 5.019464]\n",
            "[Epoch 4800/5000] [D loss: 0.158511] [G loss: 2.250825]\n",
            "[Epoch 4800/5000] [D loss: 0.081924] [G loss: 5.162484]\n",
            "[Epoch 4800/5000] [D loss: 0.353928] [G loss: 3.457795]\n",
            "[Epoch 4800/5000] [D loss: 0.279363] [G loss: 8.055896]\n",
            "[Epoch 4800/5000] [D loss: 0.016069] [G loss: 2.545202]\n",
            "[Epoch 4850/5000] [D loss: 0.210469] [G loss: 1.586196]\n",
            "[Epoch 4850/5000] [D loss: 0.169184] [G loss: 1.996922]\n",
            "[Epoch 4850/5000] [D loss: 0.183455] [G loss: 3.533713]\n",
            "[Epoch 4850/5000] [D loss: 0.834032] [G loss: 5.689998]\n",
            "[Epoch 4850/5000] [D loss: 0.260618] [G loss: 1.965111]\n",
            "[Epoch 4850/5000] [D loss: 0.279486] [G loss: 3.924632]\n",
            "[Epoch 4850/5000] [D loss: 0.144821] [G loss: 5.745940]\n",
            "[Epoch 4850/5000] [D loss: 1.467359] [G loss: 4.564813]\n",
            "[Epoch 4900/5000] [D loss: 0.560232] [G loss: 8.224264]\n",
            "[Epoch 4900/5000] [D loss: 0.059890] [G loss: 6.712107]\n",
            "[Epoch 4900/5000] [D loss: 0.053523] [G loss: 6.727823]\n",
            "[Epoch 4900/5000] [D loss: 0.165561] [G loss: 1.547003]\n",
            "[Epoch 4900/5000] [D loss: 0.227042] [G loss: 4.846134]\n",
            "[Epoch 4900/5000] [D loss: 0.017151] [G loss: 5.370617]\n",
            "[Epoch 4900/5000] [D loss: 0.879777] [G loss: 3.770993]\n",
            "[Epoch 4900/5000] [D loss: 0.212952] [G loss: 4.134931]\n",
            "[Epoch 4950/5000] [D loss: 0.084780] [G loss: 4.142286]\n",
            "[Epoch 4950/5000] [D loss: 0.190077] [G loss: 6.708623]\n",
            "[Epoch 4950/5000] [D loss: 0.128659] [G loss: 6.834105]\n",
            "[Epoch 4950/5000] [D loss: 0.959919] [G loss: 2.519888]\n",
            "[Epoch 4950/5000] [D loss: 0.130760] [G loss: 2.357845]\n",
            "[Epoch 4950/5000] [D loss: 0.156164] [G loss: 2.600932]\n",
            "[Epoch 4950/5000] [D loss: 0.175730] [G loss: 3.384758]\n",
            "[Epoch 4950/5000] [D loss: 0.046812] [G loss: 3.424517]\n",
            "[Epoch 5000/5000] [D loss: 0.539382] [G loss: 5.407200]\n",
            "[Epoch 5000/5000] [D loss: 0.107795] [G loss: 3.878826]\n",
            "[Epoch 5000/5000] [D loss: 0.090927] [G loss: 5.016500]\n",
            "[Epoch 5000/5000] [D loss: 0.279654] [G loss: 4.939620]\n",
            "[Epoch 5000/5000] [D loss: 0.262220] [G loss: 4.884788]\n",
            "[Epoch 5000/5000] [D loss: 0.058513] [G loss: 3.738037]\n",
            "[Epoch 5000/5000] [D loss: 0.054460] [G loss: 4.749933]\n",
            "[Epoch 5000/5000] [D loss: 0.021272] [G loss: 3.117266]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHeR1GhqtYKa",
        "colab_type": "text"
      },
      "source": [
        "##### Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAilGt3ttYKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(generator.state_dict(), 'generator')\n",
        "torch.save(discriminator.state_dict(), 'discriminator')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyPdig4X_Xq5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "fce30678-ad86-45b4-f44b-48eb84e612e8"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chest-xray-pneumonia.zip  \u001b[0m\u001b[01;34mcovid-chestxray-dataset\u001b[0m/  inception.h5    \u001b[01;34mpatients\u001b[0m/\n",
            "cnn.h5                    discriminator             \u001b[01;34moutput_co\u001b[0m/      vgg15.h5\n",
            "\u001b[01;34mco\u001b[0m/                       generator                 output_covid19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBLuPDautYKc",
        "colab_type": "text"
      },
      "source": [
        "##### function to save images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4GfAleRtYKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_image(n_row, batches_done):\n",
        "    z = Variable(Tensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))\n",
        "    gen_imgs = generator(z)\n",
        "    save_image(gen_imgs.data, \"./output_co/%d.png\" % batches_done, nrow=n_row, normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5QKyP8VtYKf",
        "colab_type": "text"
      },
      "source": [
        "##### Generate pictures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddnj59GHtYKg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "03d2d6d2-7ea4-400c-d6c0-73b1f2c6d3c6"
      },
      "source": [
        "images = 0\n",
        "\n",
        "for epoch in range(1, 2_50 + 1): \n",
        "    for i, (imgs, _) in enumerate(dataloader, 1):\n",
        "        \n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Adversarial ground truths\n",
        "            valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "            fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "            # Configure input\n",
        "            real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "            batches_done = epoch * len(dataloader) + i\n",
        "            sample_image(n_row=5, batches_done=batches_done)\n",
        "            images += 25\n",
        "            \n",
        "    if images % 5_000 == 0:\n",
        "        print(f'Pictures created: {images:,}')\n",
        "        \n",
        "    if len(os.listdir(os.path.join(os.getcwd(), 'output_co')))  >= 1_000:\n",
        "        print('\\n images successfully generated.')\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " images successfully generated.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZx0r36fv_Em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}